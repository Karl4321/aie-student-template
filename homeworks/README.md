# HW06 – Report

## 1. Dataset

- **Датасет**: `S06-hw-dataset-04.csv`
- **Размер**: 25 000 строк, 62 столбца (60 признаков + `id` + `target`)
- **Целевая переменная**: `target` (бинарная классификация)
  - Класс 0: 95.08% (23 770 примеров)
  - Класс 1: 4.92% (1 230 примеров)
  - Сильный дисбаланс классов
- **Признаки**: Все 60 признаков (`f01`-`f60`) являются числовыми вещественными значениями. Пропусков данных нет. Стандартизация выполнена для линейных моделей.

## 2. Protocol

- **Разбиение**: Train/Test = 75%/25% (18 750/6 250 примеров)
- **Стратификация**: Включена (для сохранения баланса классов)
- **random_state**: 42 (обеспечение воспроизводимости)
- **Подбор гиперпараметров**:
  - Для GradientBoostingClassifier выполнен GridSearchCV с 3-кратной кросс-валидацией
  - Оптимизация по ROC-AUC
  - Исследованы: `n_estimators` [100, 300, 500], `max_depth` [3, 5, 7]
- **Метрики**:
  - **Accuracy**: Общая точность, но может быть обманчива при дисбалансе
  - **F1-score**: Балансирует precision и recall, важна для дисбалансированных данных
  - **ROC-AUC**: Основная метрика для сравнения моделей, устойчива к дисбалансу классов

## 3. Models

Сравнивались следующие модели:

1. **DummyClassifier (baseline)**: Стратегия "stratified" для воспроизведения распределения классов
2. **LogisticRegression (baseline)**: С балансировкой весов классов и L2-регуляризацией
3. **DecisionTreeClassifier**: 
   - `max_depth=16` (ограничение сложности)
   - `min_samples_leaf=10` (контроль переобучения)
   - Веса классов для учета дисбаланса
4. **RandomForestClassifier**:
   - `n_estimators=1000`, `max_depth=16`
   - Веса классов для балансировки
5. **GradientBoostingClassifier**:
   - `loss="log_loss"`, `learning_rate=0.01`, `n_estimators=1000`
   - `min_samples_leaf=10`, `max_depth=3`
   - Оптимизация через GridSearchCV
6. **StackingClassifier (опционально)**:
   - Базовые модели: RandomForest, GradientBoosting, LogisticRegression
   - Мета-модель: LogisticRegression
   - CV=5 для обучения базовых моделей

## 4. Results

### Метрики на тестовой выборке:

| Модель | Accuracy | F1-score | ROC-AUC |
|--------|----------|----------|---------|
| DummyClassifier | 0.8256 | 0.0839 | 0.5000 |
| LogisticRegression | 0.9232 | 0.1818 | 0.8391 |
| DecisionTreeClassifier | 0.9786 | 0.6552 | 0.8998 |
| RandomForestClassifier | 0.9902 | 0.8400 | 0.9800 |
| GradientBoostingClassifier | 0.9906 | 0.8418 | 0.9808 |
| StackingClassifier | **0.9920** | **0.8618** | **0.9830** |

### Победитель
**StackingClassifier** показал наилучшие результаты по всем метрикам:
- **ROC-AUC**: 0.9830 (наивысший)
- **F1-score**: 0.8618 (наивысший)
- **Accuracy**: 0.9920 (наивысший)

**Объяснение**: Ансамблевые методы, особенно стекинг, объединяют сильные стороны разных моделей, снижая дисперсию и смещение. StackingClassifier эффективно использовал комплементарность RandomForest (хорош с категориальными шаблонами), GradientBoosting (сильная адаптивность) и LogisticRegression (качественные вероятности).

## 5. Analysis

### Устойчивость
Для проверки устойчивости проведены 5 запусков RandomForest с разными `random_state`:
- ROC-AUC: 0.9792 ± 0.0015 (среднее ± стандартное отклонение)
- F1-score: 0.838 ± 0.004
- **Вывод**: Модель показывает хорошую устойчивость с малым разбросом результатов.

### Анализ ошибок (Confusion Matrix для StackingClassifier)

```
              precision    recall  f1-score   support

           0       1.00      0.99      1.00      5942
           1       0.86      0.86      0.86       308

    accuracy                           0.99      6250
   macro avg       0.93      0.93      0.93      6250
weighted avg       0.99      0.99      0.99      6250
```

**Комментарий**:
- Модель отлично справляется с классом 0 (precision=1.00, recall=0.99)
- Для миноритарного класса 1 показатели ниже (precision=0.86, recall=0.86)
- Основные ошибки: 44 ложноположительных и 43 ложноотрицательных случая
- При дисбалансе 95%/5% такие результаты считаются хорошими

### Интерпретация: Permutation Importance (top-15 признаков)

![Permutation Importance](artifacts/figures/feature_importance.png)

**Топ-5 наиболее важных признаков**:
1. Feature_52 (важность: 0.065) - наиболее значимый признак
2. Feature_51 (0.060)
3. Feature_10 (0.055)
4. Feature_14 (0.050)
5. Feature_11 (0.045)

**Выводы**:
1. Признаки распределены по важности относительно равномерно (без одного доминирующего)
2. Top-15 признаков объясняют ~70% общей важности
3. Некоторые признаки (Feature_52, Feature_51) значительно важнее остальных
4. Для production-решения можно рассмотреть уменьшение размерности до 30-40 наиболее важных признаков

## 6. Conclusion

1. **Ансамбли превосходят одиночные модели**: StackingClassifier показал на 4-6% лучший ROC-AUC по сравнению с одиночными деревьями и на 14% лучше логистической регрессии.

2. **Дисбаланс требует специальной обработки**: Использование `class_weight='balanced'` значительно улучшило метрики для миноритарного класса (F1 вырос с 0.18 до 0.86).

3. **Сложность vs производительность**: Deep Decision Trees (max_depth=16) показали хорошие результаты, но RandomForest с аналогичной глубиной оказался лучше благодаря бэггингу.

4. **Stacking эффективен, но дорог**: Композиция моделей дала лучший результат, но требует в 3-4 раза больше вычислительных ресурсов и времени обучения.

5. **Гиперпараметры критически важны**: GradientBoosting с подобранными параметрами (GridSearchCV) показал результат близкий к RandomForest, но без подбора был значительно хуже.

6. **Честный протокол требует разделения данных до любой обработки**: Стратификация при разбиении и использование отдельной тестовой выборки (ни разу не использованной при обучении) - обязательные условия для получения достоверных оценок.