# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 9 столбцов)
- Признаки: Все числовые (8 числовых признаков + sample_id)
- Пропуски: Нет пропусков (SimpleImputer не требовался)
- "Подлости" датасета: (разные шкалы / высокая размерность / сферическая структура)

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 4 столбца)
- Признаки: Все числовые (3 признака: x1, x2, z_noise + sample_id)
- Пропуски: Нет пропусков (SimpleImputer не требовался)
- "Подлости" датасета: (шумовой признак / нелинейная структура / разная плотность / выбросы)

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (10000 строк, 7 столбцов)
- Признаки: Все числовые (6 числовых признаков + sample_id)
- Пропуски: Нет пропусков (SimpleImputer не требовался)
- "Подлости" датасета: (комбинация форм кластеров / смесь плотностей / умеренная размерность)

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг**: StandardScaler для масштабирования; удаление sample_id; пропусков нет → SimpleImputer не применялся
- **Поиск гиперпараметров**:
  - KMeans: диапазон k от 2 до 11, выбор по максимуму silhouette score
  - DBSCAN: eps 0.10-0.90 с шагом 0.01, min_samples 8-40 с шагом 1
  - Критерий: максимизация silhouette score при наличии ≥2 кластеров
- **Метрики**: silhouette_score, davies_bouldin_score, calinski_harabasz_score; для DBSCAN метрики считались без шума (-1)
- **Визуализация**: PCA 2D с n_components=2, random_state=42 для всех датасетов

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

### Dataset 1:
- KMeans: поиск k в [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], random_state=42, n_init=10
- DBSCAN: eps в [0.30-0.89], min_samples в [20-48]

### Dataset 2:
- KMeans: поиск k в [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], random_state=42, n_init=10
- DBSCAN: eps в [0.10-0.89], min_samples в [8-39]

### Dataset 3:
- KMeans: поиск k в [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], random_state=42, n_init=10
- DBSCAN: eps в [0.10-0.89], min_samples в [8-39]

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, k=2
- Метрики (silhouette / DB / CH): 0.522 / 0.685 / 11786.95
- Если был DBSCAN: доля шума 0.0% (eps=0.60, min_samples=38, silhouette=0.401)
- Коротко: KMeans показывает лучшие метрики, данные имеют сферическую структуру с равномерной плотностью

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN, eps=0.75, min_samples=14
- Метрики (silhouette / DB / CH): 0.552 / 0.457 / 124.35
- Доля шума: 0.0%
- Коротко: DBSCAN превосходит KMeans, данные содержат шум и нелинейную структуру

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, k=3
- Метрики (silhouette / DB / CH): 0.315 / 1.160 / 9427.50
- Если был DBSCAN: доля шума 1.2% (eps=0.84, min_samples=8, silhouette=0.312)
- Коротко: KMeans показывает немного лучшие метрики, данные имеют смешанную структуру

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему? На Dataset 2 из-за нелинейной структуры и шумового признака
- Где DBSCAN/иерархическая кластеризация выигрывают и почему? На Dataset 2 благодаря устойчивости к шуму и нелинейным границам
- Что сильнее всего влияло на результат: структура данных (сферическая vs нелинейная) и наличие шума

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: 10 запусков KMeans с разными random_state (1-10) на Dataset 1 при k=5
- Результаты: silhouette 0.355 ± 0.000, inertia 25476 ± 0.0, Adjusted Rand Index 1.000
- Вывод: абсолютная устойчивость благодаря чёткой структуре данных

### 5.3 Интерпретация кластеров

- Метод: анализ центроидов и распределения признаков
- Dataset 1: два чётких кластера (46.5% и 53.5% точек)
- Dataset 2: два кластера с нелинейными границами (все точки отнесены)
- Dataset 3: три кластера разной компактности
- Вывод: кластеры имеют разумную интерпретацию через профили признаков

## 6. Conclusion

1. Нет универсального метода: KMeans для сферических кластеров, DBSCAN для данных с шумом
2. Важность масштабирования: критически для всех методов
3. Метрики должны дополнять друг друга: использовать silhouette, DB и CH вместе
4. Визуализация PCA незаменима для понимания структуры данных
5. Параметры DBSCAN критичны: требуют тщательного подбора
6. Устойчивость важна: KMeans может быть устойчивым на чётко структурированных данных
7. Контекст решает: выбор метода зависит от природы данных
8. Экспериментирование необходимо: тестировать несколько методов с разными параметрами